{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_file(filename, filepath):\n",
    "    \"\"\"\n",
    "    Opens the pickled dataframe stored at the specified location.\n",
    "    ---\n",
    "    IN: string\n",
    "    OUT: pandas dataframe\n",
    "    \"\"\"\n",
    "    with open(filepath + filename, 'rb') as picklefile: \n",
    "        df = pickle.load(picklefile)\n",
    "        \n",
    "    if df.empty:\n",
    "        print(f\"Dataframe at {filename} is empty.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Stock & Wikipedia Data by Week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to improve this so it takes the open on Monday and close on Friday, not the mean of five opens and closes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath_stock_wiki='/Users/Joe/Documents/Metis/Projects/metis-two-Luther/data/combined-wiki-price-data/'\n",
    "stock_files = os.listdir(filepath_stock_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Must write a custom function to get the opening and closing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = open_file(stock_files[10], filepath_stock_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.set_index('date', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df['close'].resample(\"W\").first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aggregation_functions = {'size (bytes)': [sum],\n",
    "                         'size_delta': [sum],\n",
    "                         'minor_edit': [sum],\n",
    "                         'edit_count': [sum],\n",
    "                         'high': [np.max],\n",
    "                         'low':  [np.min],\n",
    "                         'volume': [sum],\n",
    "                         'adj_high': [np.max],\n",
    "                         'adj_low':  [np.min],\n",
    "                         'adj_volume': [sum]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_by_week(filename, agg_func = aggregation_functions):\n",
    "    # Open dataframe\n",
    "    filepath_stock_wiki='/Users/Joe/Documents/Metis/Projects/metis-two-Luther/data/combined-wiki-price-data/'\n",
    "    df = open_file(filename, filepath_stock_wiki)\n",
    "    \n",
    "    # Sample by Week\n",
    "    df.set_index('date', drop=True, inplace=True)\n",
    "    df_weekly = df.resample(\"W\").agg(agg_func)\n",
    "    \n",
    "    # For opening and closing values, take the first and last of the week, respectively\n",
    "    opening = df['open'].resample(\"W\").first()\n",
    "    closing = df['close'].resample(\"W\").last()\n",
    "    opening_adj = df['adj_open'].resample(\"W\").first()\n",
    "    closing_adj = df['adj_close'].resample(\"W\").last()\n",
    "    \n",
    "    df_weekly.columns = df_weekly.columns.droplevel(1)\n",
    "    df_weekly = df_weekly.join([opening, closing, opening_adj, closing_adj])\n",
    "    return df_weekly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Stock Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_stock_targets(df): \n",
    "    # Non-Minor Edit\n",
    "    df['non-minor_edit'] = df['edit_count'] - df['minor_edit']\n",
    "    \n",
    "    # Create Stock Targets\n",
    "    df['percent_change'] = (df['close'] - df['open'])/df['open']\n",
    "    df['swing'] = (df['high'] - df['low'])/df['open']\n",
    "    \n",
    "    df['percent_adj_change'] = (df['adj_close'] - df['adj_open'])/df['adj_open']\n",
    "    df['adj_swing'] = (df['adj_high'] - df['adj_low'])/df['adj_open']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Open and Format Trend Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google quantifies search quatities as such:  \n",
    "\n",
    "Numbers represent search interest relative to the highest point on the chart for the given region and time. A value of 100 is the peak popularity for the term. A value of 50 means that the term is half as popular. Likewise a score of 0 means the term was less than 1% as popular as the peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath_trends = '/Users/Joe/Documents/Metis/Projects/metis-two-Luther/data/google-trends/'\n",
    "trend_files = [file for file in os.listdir(filepath_trends) if file.startswith('.') == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trend_dataframe(filename):\n",
    "    # Load Data\n",
    "    filepath_trends = '/Users/Joe/Documents/Metis/Projects/metis-two-Luther/data/google-trends/'\n",
    "    df_trend = pd.read_csv(filepath_trends + filename)\n",
    "    \n",
    "    # Format Data\n",
    "    df_trend = df_trend.iloc[1:]\n",
    "    df_trend.rename(columns={'Category: All categories': 'search_interest'}, inplace=True)\n",
    "    df_trend.index = pd.to_datetime(df_trend.index)\n",
    "    \n",
    "    return df_trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Datasets  \n",
    "Conveniently, they both increment on Sunday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trend_filename(wiki_filename):\n",
    "    abbrev = wiki_filename.replace('wikipedia-and-stock-history-', '').replace('.pkl', '')\n",
    "    return abbrev + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def abbrev_from_filename(wiki_filename):\n",
    "    abbrev = wiki_filename.replace('wikipedia-and-stock-history-', '').replace('.pkl', '')\n",
    "    return abbrev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_wiki_and_trend(wiki_filename):\n",
    "    # Open Wiki/Stock df and resample by week\n",
    "    try:\n",
    "        df_wiki = sample_by_week(wiki_filename, agg_func = aggregation_functions)\n",
    "    except:\n",
    "        print(f\"Error on {wiki_filename}\")\n",
    "        raise\n",
    "    \n",
    "    # Create Stock Targets\n",
    "    df_wiki = create_stock_targets(df_wiki)\n",
    "    \n",
    "    # Get the name of trends file from the abbrev in the stock/wiki filename\n",
    "    trend_csv = trend_filename(wiki_filename)\n",
    "    try:\n",
    "        df_trend = trend_dataframe(trend_csv)\n",
    "        df = pd.merge(df_wiki, df_trend, how='inner', left_index=True, right_index=True)\n",
    "        return df\n",
    "    except:\n",
    "        # There is no trend data for this firm\n",
    "        print(f'Collect trend data for {trend_csv}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compression\n",
    "def save_file(df, abbrev):\n",
    "    filepath = '/Users/Joe/Documents/Metis/Projects/metis-two-Luther/data/stock_wiki_trend_dataframes/'\n",
    "    compressor = 'blosc'\n",
    "    \n",
    "    filename = filepath + abbrev + '.h5'\n",
    "    df.to_hdf(filename, 'table', mode='w', complevel=9, complib=compressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect trend data for BBBY.csv\n",
      "Not saving a merged dataframe for BBBY\n",
      "Dataframe at wikipedia-and-stock-history-CTRP.pkl is empty.\n",
      "Dataframe at wikipedia-and-stock-history-FLEX.pkl is empty.\n",
      "Dataframe at wikipedia-and-stock-history-JD.pkl is empty.\n",
      "Dataframe at wikipedia-and-stock-history-LBTYK.pkl is empty.\n",
      "Dataframe at wikipedia-and-stock-history-NTES.pkl is empty.\n",
      "Dataframe at wikipedia-and-stock-history-NXPI.pkl is empty.\n",
      "Dataframe at wikipedia-and-stock-history-QVCA.pkl is empty.\n",
      "Dataframe at wikipedia-and-stock-history-SHPG.pkl is empty.\n",
      "Collect trend data for URBN.csv\n",
      "Not saving a merged dataframe for URBN\n"
     ]
    }
   ],
   "source": [
    "# Merge and save every company collected\n",
    "for file in stock_files:\n",
    "    df = open_file(file, filepath_stock_wiki)\n",
    "    if df.empty:\n",
    "        # There is no data here. Skip this step.\n",
    "        continue\n",
    "    \n",
    "    abbrev = abbrev_from_filename(file)\n",
    "    df = merge_wiki_and_trend(file)\n",
    "    try:\n",
    "        save_file(df, abbrev)\n",
    "    except:\n",
    "        print(f\"Not saving a merged dataframe for {abbrev}\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This gives us combined Wikipedia, Google Trend, and Stock data for 112 companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
